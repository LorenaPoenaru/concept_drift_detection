{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef5cf20",
   "metadata": {},
   "source": [
    "Observations one hot encoded data and drift detectors performances:\n",
    "\n",
    "- Experiment 1: One hot encoding of categorical data & no scaling - \n",
    "- Experiment 2: One hot encoding of categorical data & MinMaxScaling - \n",
    "- Experiment 3: One hot encoding of categorical data & StandardScaler - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba192d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skmultiflow.drift_detection import DDM\n",
    "from skmultiflow.drift_detection import EDDM\n",
    "from skmultiflow.drift_detection import ADWIN\n",
    "from skmultiflow.drift_detection import HDDM_A\n",
    "from skmultiflow.drift_detection import HDDM_W\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_train = 30000\n",
    "length_of_test = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1545e47e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train(dataset, length_of_train):\n",
    "    X_train = df.iloc[0:length_of_train]\n",
    "    X_train = X_train.drop(['class'], axis = 1)\n",
    "    y_train = df['class'][0:length_of_train]\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11946b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test(dataset, start_from_sample, length_of_test):\n",
    "    X_test = df.iloc[start_from_sample:start_from_sample+length_of_test]\n",
    "    X_test = X_test.drop(['class'], axis = 1)\n",
    "    y_test = df['class'][start_from_sample:start_from_sample+length_of_test]\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894aba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Others have: 1 for incorrect prediction and 0 for correct prediction\n",
    "def drift_detect_function(drift_detector, y_pred):\n",
    "    baches_with_drift = []\n",
    "    # go through every batch\n",
    "    for i in tqdm(range(0, int((len(df)-length_of_train)/length_of_test))):\n",
    "        # go through every label of one batch\n",
    "        for j in range(0, len(list(y_test))):\n",
    "            label_difference = abs(list(y_test)[j] - y_pred[i][j])\n",
    "            drift_detector.add_element(label_difference)\n",
    "            if(drift_detector.detected_change()):\n",
    "                #print('Drift in performance detected at sample {}'.format(i))\n",
    "                baches_with_drift.append(i)\n",
    "    return baches_with_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9903a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADWIN has: 1 for correct prediction and 0 for incorrect prediction\n",
    "def drift_detect_function_ADWIN(drift_detector, y_pred):\n",
    "    # go through every batch\n",
    "    batches_with_drift = []\n",
    "    for i in tqdm(range(0, int((len(df)-length_of_train)/length_of_test))):\n",
    "        # go through every label of one batch\n",
    "        for j in range(0, len(list(y_test))):\n",
    "            label_difference = abs(list(y_test)[j] - y_pred[i][j])\n",
    "            label_difference_final = 1 - label_difference\n",
    "            drift_detector.add_element(label_difference_final)\n",
    "            if(drift_detector.detected_change()):\n",
    "                #print('Drift in performance detected at sample {}'.format(i))\n",
    "                batches_with_drift.append(i)\n",
    "    return batches_with_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c388c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_times_detection(array):\n",
    "    results = []\n",
    "\n",
    "    \n",
    "    if(len(array)==0):\n",
    "        results = 'nothing_detected'\n",
    "    else:\n",
    "        for i in range(0, len(array)):\n",
    "            results.append(int(array[i]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea29f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_false_positive(array_batches):\n",
    "    \n",
    "    drift_start = 2\n",
    "    \n",
    "    if(len(array_batches)>0): \n",
    "        \n",
    "        if(len([x for x in array_batches if x<drift_start])>0):\n",
    "            return(len([x for x in array_batches if x<drift_start])/drift_start)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    else:\n",
    "        return 'nothing_detected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b837132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_latency(array_batches):\n",
    "    no_batches_with_drift = 5\n",
    "    drift_start = 2\n",
    "    \n",
    "    if(len(array_batches)>0):  \n",
    "        #print(np.array(array_pr)>=drift_type_start)\n",
    "        #print(np.argwhere(np.array(array_pr)>=drift_type_start).size==0)\n",
    "        \n",
    "        if(np.argwhere(np.array(array_batches)>=drift_start).size==0):\n",
    "            latency_score = 'nothing_detected' \n",
    "        else:\n",
    "            batch_drift_detected = array_batches[np.argwhere(np.array(array_batches)>=drift_start)[0][0]]\n",
    "            latency_score = (batch_drift_detected - drift_start)/no_batches_with_drift\n",
    "        return latency_score\n",
    "    else:\n",
    "        return 'nothing_detected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fe36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450f78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080459e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['sea', 'agraw1', 'agraw2']\n",
    "drift_types = ['abrupt', 'gradual']\n",
    "random_seeds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "driftwidth_values = ['05', '1', '5', '10', '20']\n",
    "noise_values = [0, 10, 20]\n",
    "balance_types = ['imbalanced', 'balanced']\n",
    "\n",
    "\n",
    "final_results_df = pd.DataFrame(columns=['dataset', 'drift_type', 'drift_width', 'detector', 'distance/test', \n",
    "                                         'drift_batches','noise_value', 'balance_type', 'false_positive_rate', \n",
    "                                         'latency', 'random_seed'])\n",
    "\n",
    "\n",
    "for data_name in datasets:\n",
    "    for noise_value in noise_values:\n",
    "        for balance_type in balance_types:\n",
    "            for random_seed in random_seeds:\n",
    "                for drift_type in drift_types:\n",
    "                        for driftwidth_value in driftwidth_values:\n",
    "\n",
    "                            # to only go through abrupt once\n",
    "                            if drift_type == 'abrupt' and driftwidth_values.index(driftwidth_value) > 0:\n",
    "                                break\n",
    "\n",
    "                            #path for local\n",
    "                            path = '../../../../Documents/phd_related/data_sets_concept_drift/moa_datasets/'\n",
    "\n",
    "\n",
    "                            dataset_name = data_name\n",
    "\n",
    "\n",
    "                            drift_width = '' if drift_type != 'gradual' else f'_{driftwidth_value}'\n",
    "                            drift_width_column = drift_width if drift_type == 'abrupt' else driftwidth_value\n",
    "\n",
    "                            dataset_path = path + f'{dataset_name}_{random_seed}_{drift_type}_drift_{noise_value}_noise_{balance_type}{drift_width}.arff' \n",
    "\n",
    "                            #print(dataset_path)\n",
    "                            # count how much it takes to run\n",
    "                            #now = datetime.datetime.now()\n",
    "                            #print('hour '+ str(int(now.hour)) + ' minute ' +  str(int(now.minute)) +' second ' + str(int(now.second)))\n",
    "\n",
    "                            # read data \n",
    "                            data = arff.loadarff(dataset_path)\n",
    "\n",
    "                            df = pd.DataFrame(data[0])\n",
    "                            df = df.replace(df['class'].unique()[0], 0)\n",
    "                            df = df.replace(df['class'].unique()[1], 1)\n",
    "\n",
    "                            # extract labels\n",
    "\n",
    "                            labels = list(df['class'])\n",
    "\n",
    "                            # one hot encoding if needed\n",
    "\n",
    "                            if(dataset_name.startswith('agraw')):\n",
    "                                one_hot_encoded_data = pd.get_dummies(df, columns = ['elevel', 'car', 'zipcode'])\n",
    "                                df = one_hot_encoded_data\n",
    "\n",
    "                            # split train test\n",
    "\n",
    "                            X_train, y_train = create_train(df, length_of_train)\n",
    "                            \n",
    "                            # in case of class imbalance, apply smote to the training data to balance the classes\n",
    "                            \n",
    "                            if(balance_type == 'imbalanced'):\n",
    "                                oversample = SMOTE()\n",
    "                                X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "                            # Train models\n",
    "\n",
    "                            gnb = GaussianNB()\n",
    "                            naive_bayes = gnb.fit(X_train, y_train)\n",
    "\n",
    "                            ht = HoeffdingTreeClassifier()\n",
    "                            hoeffding_tree = ht.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "                            adb = AdaBoostClassifier(n_estimators= 100, random_state=0)\n",
    "                            adaboost = adb.fit(X_train, y_train)\n",
    "\n",
    "                            xgb = XGBClassifier()\n",
    "                            xgboost = xgb.fit(X_train, y_train)\n",
    "\n",
    "                            lgb = LGBMClassifier()\n",
    "                            lightgbm = lgb.fit(X_train, y_train)\n",
    "\n",
    "                            # Test on testing batches \n",
    "\n",
    "                            start_from_sample = length_of_train\n",
    "\n",
    "                            y_pred_naivebayes = []\n",
    "                            y_pred_hoftree = []\n",
    "                            y_pred_adaboost = []\n",
    "                            y_pred_xgboost = []\n",
    "                            y_pred_lightgbm = []\n",
    "\n",
    "\n",
    "                            for i in tqdm(range(0, int((len(df)-length_of_train)/length_of_test))):\n",
    "                                X_test, y_test = create_test(df, start_from_sample, length_of_test)\n",
    "                                start_from_sample = start_from_sample + length_of_test\n",
    "                                # naive bayes\n",
    "                                y_pred_nb = naive_bayes.predict(X_test)\n",
    "                                y_pred_naivebayes.append(y_pred_nb)\n",
    "\n",
    "                                # hoeffding tree\n",
    "                                y_pred_ht = hoeffding_tree.predict(np.array(X_test))\n",
    "                                y_pred_hoftree.append(y_pred_ht)\n",
    "                                # adaboost\n",
    "                                y_pred_adb = adaboost.predict(X_test)\n",
    "                                y_pred_adaboost.append(y_pred_adb)\n",
    "                                # xgboost\n",
    "                                y_pred_xgb = xgboost.predict(X_test)\n",
    "                                y_pred_xgboost.append(y_pred_xgb)\n",
    "                                # lightgbm\n",
    "                                y_pred_lgbm = lightgbm.predict(X_test)\n",
    "                                y_pred_lightgbm.append(y_pred_lgbm)\n",
    "\n",
    "\n",
    "\n",
    "                            y_pred_dict = {'NaiveBayes': y_pred_naivebayes, \n",
    "                               'HoeffdingTree' : y_pred_hoftree, \n",
    "                               'Adaboost' : y_pred_adaboost,\n",
    "                               'XGBoost' : y_pred_xgboost,\n",
    "                               'LightGBM' : y_pred_lightgbm}\n",
    "\n",
    "\n",
    "                            # Drift Detectors \n",
    "\n",
    "                            drift_batches = []\n",
    "                            classifiers = []\n",
    "                            detectors = []\n",
    "\n",
    "                            for i in tqdm(range(0, len(list(y_pred_dict.keys())))):\n",
    "\n",
    "                                classifiers.append(list(y_pred_dict.keys())[i])\n",
    "                                print(list(y_pred_dict.keys())[i])\n",
    "\n",
    "                                #detector DDM\n",
    "                                detectors.append('DDM')\n",
    "\n",
    "                                #print(list(y_pred_dict.values())[i])\n",
    "                                drifts_ddm = drift_detect_function(DDM(), list(y_pred_dict.values())[i])\n",
    "                                drifts_ddm = list(dict.fromkeys(drifts_ddm))\n",
    "\n",
    "                                drift_batches.append(drifts_ddm)\n",
    "                                #detector EDDM\n",
    "                                detectors.append('EDDM')\n",
    "\n",
    "                                drifts_eddm = drift_detect_function(EDDM(), list(y_pred_dict.values())[i])\n",
    "                                drifts_eddm = list(dict.fromkeys(drifts_eddm))\n",
    "\n",
    "                                drift_batches.append(drifts_eddm)\n",
    "                                #detector ADWIN\n",
    "                                detectors.append('ADWIN')\n",
    "\n",
    "                                drifts_adwin = drift_detect_function_ADWIN(ADWIN(), list(y_pred_dict.values())[i])\n",
    "                                drifts_adwin = list(dict.fromkeys(drifts_adwin))\n",
    "\n",
    "                                drift_batches.append(drifts_adwin)\n",
    "                                #detector HDDM_W\n",
    "                                detectors.append('HDDM_W')\n",
    "\n",
    "                                drifts_hddmw = drift_detect_function(HDDM_W(), list(y_pred_dict.values())[i])\n",
    "                                drifts_hddmw = list(dict.fromkeys(drifts_hddmw))\n",
    "\n",
    "                                drift_batches.append(drifts_hddmw)\n",
    "                                # detector HDDM_A\n",
    "                                detectors.append('HDDM_A')\n",
    "\n",
    "                                drifts_hddma = drift_detect_function(HDDM_A(), list(y_pred_dict.values())[i])\n",
    "                                drifts_hddma = list(dict.fromkeys(drifts_hddma))\n",
    "\n",
    "                                drift_batches.append(drifts_hddma)\n",
    "\n",
    "                            # make each classifier appear 5 times because we have 5 drift detectors\n",
    "                            classifiers_df = list(itertools.chain.from_iterable(itertools.repeat(x, 5) for x in classifiers))\n",
    "\n",
    "                            # ensure that each element in drift batches is a list\n",
    "                            for i in range(0, len(drift_batches)):\n",
    "                                drift_batches[i] = list(drift_batches[i])\n",
    "\n",
    "                            test_length = [length_of_test for i in range(len(classifiers_df))]\n",
    "\n",
    "                            df_error_based = pd.DataFrame({'dataset' : f'{dataset_name}',\n",
    "                                                               'drift_type': f'{drift_type}',\n",
    "                                                               'drift_width': f'{drift_width_column}',\n",
    "                                                               'detector': detectors,\n",
    "                                                               'classifier': classifiers_df, \n",
    "                                                               'drift_batches': drift_batches,\n",
    "                                                               'noise_value': noise_value,\n",
    "                                                               'balance_type': balance_type})\n",
    "\n",
    "\n",
    "\n",
    "                            # Evaluation metrics\n",
    "\n",
    "                            abrupt_drift_start = 2\n",
    "                            gradual_drift_start = 2\n",
    "\n",
    "                            false_positive_rate = []\n",
    "                            latency = []\n",
    "\n",
    "                            for i in range(0, len(df_error_based.drift_batches)):\n",
    "\n",
    "                                false_positive_rate.append(compute_metric_false_positive(df_error_based.drift_batches[i]))\n",
    "                                latency.append(compute_metric_latency(df_error_based.drift_batches[i]))\n",
    "\n",
    "                            df_error_based['false_positive_rate'] = false_positive_rate\n",
    "                            df_error_based['latency'] = latency\n",
    "                            df_error_based['random_seed'] = [random_seed for i in range(len(df_error_based.dataset))]\n",
    "\n",
    "                            final_results_df = pd.concat([final_results_df, df_error_based])\n",
    "\n",
    "                            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56765f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df.to_csv('./ERB_drift_detection_synthetic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f96fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed0e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39576b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1d68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbc1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea7386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
