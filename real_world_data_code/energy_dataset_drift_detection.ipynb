{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb7b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from skmultiflow.drift_detection import DDM\n",
    "from skmultiflow.drift_detection import EDDM\n",
    "from skmultiflow.drift_detection import ADWIN\n",
    "from skmultiflow.drift_detection import HDDM_A\n",
    "from skmultiflow.drift_detection import HDDM_W\n",
    "\n",
    "from datetime import timedelta, date\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import groupby\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from math import log2\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from scipy.spatial.distance import chebyshev\n",
    "from scipy.spatial.distance import kulsinski\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import sqeuclidean\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b328dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_detect_function(drift_detector, y_true, y_pred, no_batches):\n",
    "    batches_with_drift = []\n",
    "    for i in range(0, no_batches):\n",
    "        label_difference = abs(y_true[i] - y_pred[i])\n",
    "        #print(label_difference)\n",
    "        \n",
    "        for j in range(0, len(label_difference)):\n",
    "            drift_detector.add_element(list(label_difference)[j])\n",
    "\n",
    "            if(drift_detector.detected_change()):\n",
    "                batches_with_drift.append(i)\n",
    "    return batches_with_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caba2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADWIN has: 1 for correct prediction and 0 for incorrect prediction\n",
    "def drift_detect_function_ADWIN(drift_detector, y_true, y_pred, no_batches):\n",
    "    \n",
    "    batches_with_drift = []\n",
    "    for i in range(0, no_batches):\n",
    "        label_difference = abs(y_true[i] - y_pred[i])\n",
    "        label_difference_final = 1 - label_difference\n",
    "    \n",
    "        for j in range(0, len(label_difference_final)):\n",
    "            drift_detector.add_element(list(label_difference_final)[j])\n",
    "            if(drift_detector.detected_change()):\n",
    "                batches_with_drift.append(i)\n",
    "    return batches_with_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008dfced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    return sum(p[0][i] * log2(p[0][i]/q[0][i]) for i in range(len(p[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40197dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bhattacharyya(p, q):\n",
    "    return -np.log(sum(np.square(p[0][i]*1.0*q[0][i]) for i in range(len(p[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0016ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(X_train, bootstrapping_samples, pca=None):\n",
    "    # Extract distributions of 50 random training subsets\n",
    "    distributions_bootstrapping = []\n",
    "    for i in range(0, bootstrapping_samples):\n",
    "        # generate random number between 0 and length_of_train-length_of_test in order to have a sample of size length_of_test\n",
    "        rand = random.randint(0,len(X_train)-length_of_test)\n",
    "        # extract the distribution from the training samples random number:random number + length_of_test by means of histogram\n",
    "        if pca is not None:\n",
    "            bootstrapping_input = pca.transform(X_train[rand:rand+length_of_test])\n",
    "        else:\n",
    "            bootstrapping_input = X_train[rand:rand+length_of_test]\n",
    "        dist = sns.distplot(bootstrapping_input).get_lines()[0].get_data()[1]\n",
    "        # store distribution\n",
    "        distributions_bootstrapping.append(dist)\n",
    "        plt.close()\n",
    "    return distributions_bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eadc781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdqtrees_bootstrapping(distrib_X_train, distrib_X_test, distributions_bootstrapping, distance):\n",
    "    \n",
    "    # option to choose the similarity distance\n",
    "    \n",
    "    if(distance == 'kl_divergence'):\n",
    "        similarity_metric = kl_divergence\n",
    "    elif(distance == 'manhattan'):\n",
    "        similarity_metric = manhattan_distances\n",
    "    elif(distance == 'chebyshev'):\n",
    "        similarity_metric = chebyshev\n",
    "    elif(distance == 'kulsinski'):\n",
    "        similarity_metric = kulsinski\n",
    "    elif(distance == 'cosine'):\n",
    "        similarity_metric = cosine\n",
    "    elif(distance == 'squared_euclidean'):\n",
    "        similarity_metric = sqeuclidean\n",
    "    elif(distance == 'bhattacharyya'):\n",
    "        similarity_metric = bhattacharyya\n",
    "    \n",
    "    # Bootstrapping technique to define critical region\n",
    "    \n",
    "    dist_bootstrapping = []\n",
    "    \n",
    "    # Calculate similarity distance between training set and each of the 50 training subsets\n",
    "    for i in range(0, len(distributions_bootstrapping)):\n",
    "        dist_bootstrapping.append(similarity_metric([distrib_X_train], [distributions_bootstrapping[i]]))\n",
    "    \n",
    "    \n",
    "    # Define Critical Region\n",
    "    critical_region = np.max(dist_bootstrapping)\n",
    "    \n",
    "    # Detect Drifts between train and test\n",
    "    \n",
    "    drift_batch = None\n",
    "    \n",
    "    # Calculate distance between train and test distributions\n",
    "    \n",
    "    similarity_metric_train_test = similarity_metric([distrib_X_train], [distrib_X_test])\n",
    "    \n",
    "    if(similarity_metric_train_test>critical_region):\n",
    "        print(distance + \" : Drift Detected\" )\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce7aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_false_positive(array_batches, drift_start):\n",
    "        \n",
    "    if(len(array_batches)>0): \n",
    "        \n",
    "        if(len([x for x in array_batches if x<drift_start])>0):\n",
    "            return(len([x for x in array_batches if x<drift_start])/drift_start)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    else:\n",
    "        return 'nothing_detected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f7015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ede_drift_detector(distrib_X_train, distrib_X_test, statistical_test):\n",
    "\n",
    "    if(statistical_test == 'ks'):\n",
    "        stat_test = stats.kstest\n",
    "    elif(statistical_test == 'mw'):\n",
    "        stat_test = stats.mannwhitneyu\n",
    "    \n",
    "    v, p = stat_test(distrib_X_train, distrib_X_test)\n",
    "        \n",
    "    \n",
    "    if(p<=0.05):\n",
    "        print(\"Reject Null Hypothesis according to KS statistical test\")\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0222eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_latency(array_batches, no_batches_with_drift, drift_start):\n",
    "    \n",
    "    if(len(array_batches)>0):  \n",
    "        #print(np.array(array_pr)>=drift_type_start)\n",
    "        #print(np.argwhere(np.array(array_pr)>=drift_type_start).size==0)\n",
    "        \n",
    "        if(np.argwhere(np.array(array_batches)>=drift_start).size==0):\n",
    "            latency_score = 'nothing_detected' \n",
    "        else:\n",
    "            batch_drift_detected = array_batches[np.argwhere(np.array(array_batches)>=drift_start)[0][0]]\n",
    "            latency_score = (batch_drift_detected - drift_start)/no_batches_with_drift\n",
    "        return latency_score\n",
    "    else:\n",
    "        return 'nothing_detected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b921fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4740068",
   "metadata": {},
   "source": [
    "# Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f1c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_energy = arff.loadarff('../elecNormNew.arff')\n",
    "df_energy = pd.DataFrame(data_energy[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f1027",
   "metadata": {},
   "source": [
    "# Adding the real date column to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46702c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "day_list = list(df_energy.day)\n",
    "day_list_str = []\n",
    "for i in range(0, len(day_list)):\n",
    "    day_list_str.append(str(day_list[i]))\n",
    "day_list_str_non_duplicates = [key for key, _group in groupby(day_list_str)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e467a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_day = day_list_str_non_duplicates[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86a63d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(day_list_str_non_duplicates)):\n",
    "    prev_day = day_list_str_non_duplicates[i-1]\n",
    "    \n",
    "    current_day = day_list_str_non_duplicates[i]\n",
    "    \n",
    "    if(prev_day == 'b\\'7\\''):\n",
    "        expected_current_day = 'b\\'1\\''\n",
    "    else:\n",
    "        expected_current_day = 'b\\'' + str(int(prev_day.split('\\'')[1])+1)+ '\\''\n",
    "    if(current_day!= expected_current_day):\n",
    "        print('fjidjsfio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c71f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "date_time_energy = []\n",
    "start_date = date(1996, 5, 7)\n",
    "end_date = date(1998, 12, 7)\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    date_time_energy.append(single_date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ec00141",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_energy_df = np.repeat(date_time_energy, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37f04c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy['real_date'] = date_energy_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14ab9b",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5e1426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df_energy['class'] = labelencoder.fit_transform(df_energy['class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43638d7d",
   "metadata": {},
   "source": [
    "training until the 15th of April."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eed2d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples_index = list(df_energy[df_energy.real_date == '1997-04-15'].index)[len(list(df_energy[df_energy.real_date == '1997-05-02'].index))-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d24766",
   "metadata": {},
   "source": [
    "## Split in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dee4b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_energy[0:training_samples_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76b3ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.drop(['date', 'day', 'period', 'class', 'real_date'], axis = 1)\n",
    "label_train_data = train['class']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8eef04",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cbcb25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:16:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "naive_bayes = gnb.fit(train_data, label_train_data)\n",
    "\n",
    "ht = HoeffdingTreeClassifier()\n",
    "hoeffding_tree = ht.fit(np.array(train_data), np.array(label_train_data))\n",
    "\n",
    "adb = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "adaboost = adb.fit(train_data, label_train_data)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgboost = xgb.fit(train_data, label_train_data)\n",
    "\n",
    "lgb = LGBMClassifier()\n",
    "lightgbm = lgb.fit(train_data, label_train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf179fbb",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bba43b",
   "metadata": {},
   "source": [
    "Testing scenario: test model every week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9f4e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_energy[training_samples_index:]\n",
    "test = test.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2d4dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.drop(['date', 'day', 'period', 'class', 'real_date'], axis = 1)\n",
    "label_test_data = test['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97b3ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test = test.groupby(['real_date', 'day']).groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8ff796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_sorted = dict([(key , value) for (key, value) in sorted(dict_test.items())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e88323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_values = list(dict_test_sorted.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3446982",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_testing_batches = []\n",
    "for i in range(0, len(week_values), 7):\n",
    "    index = []\n",
    "    for j in range(0, len(week_values[i:i+7])):\n",
    "        for k in range(0, len(week_values[i:i+7][j])):\n",
    "            index.append(week_values[i:i+7][j][k])\n",
    "    indexes_testing_batches.append(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a4502e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:03<00:00, 26.88it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_naivebayes = []\n",
    "y_pred_hoftree = []\n",
    "y_pred_adaboost = []\n",
    "y_pred_xgboost = []\n",
    "y_pred_lightgbm = []\n",
    "\n",
    "df_test_labels_total = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, len(indexes_testing_batches))):\n",
    "    testing_batch = pd.DataFrame()\n",
    "    label_batch = []\n",
    "    \n",
    "    index_current_testing_batch = indexes_testing_batches[i]\n",
    "    \n",
    "    testing_batch = test_data[(index_current_testing_batch[0]):(index_current_testing_batch[-1]+1)]\n",
    "    label_batch = label_test_data[(index_current_testing_batch[0]):(index_current_testing_batch[-1]+1)]\n",
    "\n",
    "    df_test_labels_total.append(list(label_batch))\n",
    "    \n",
    "    # Naive Bayes\n",
    "    y_pred_nb = naive_bayes.predict(testing_batch)\n",
    "    y_pred_naivebayes.append(y_pred_nb)\n",
    "    \n",
    "    \n",
    "    # Hoeffding Trees\n",
    "    y_pred_ht = hoeffding_tree.predict(np.array(testing_batch))\n",
    "    y_pred_hoftree.append(y_pred_ht)\n",
    "    \n",
    "    # Adaboost\n",
    "    y_pred_adb = adaboost.predict(testing_batch)\n",
    "    y_pred_adaboost.append(y_pred_adb)\n",
    "    \n",
    "    # XGBoost\n",
    "    y_pred_xgb = xgboost.predict(testing_batch)\n",
    "    y_pred_xgboost.append(y_pred_xgb)\n",
    "    \n",
    "    # LightGBM\n",
    "    y_pred_lgbm = lightgbm.predict(testing_batch)\n",
    "    y_pred_lightgbm.append(y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "331b559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dict = {'NaiveBayes': y_pred_naivebayes, \n",
    "                   'HoeffdingTree' : y_pred_hoftree, \n",
    "                   'Adaboost' : y_pred_adaboost,\n",
    "                   'XGBoost' : y_pred_xgboost,\n",
    "                   'LightGBM' : y_pred_lightgbm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c6917c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36788632",
   "metadata": {},
   "source": [
    "# Detect Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "561e8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_batches = len(indexes_testing_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3828263",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = []\n",
    "detector_list = []\n",
    "batches_detected = []\n",
    "\n",
    "for i in range(0, len(list(y_pred_dict.keys()))):\n",
    "    classifier_list.append(list(y_pred_dict.keys())[i])\n",
    "    \n",
    "    detector_list.append('DDM')\n",
    "    batches_detected.append(drift_detect_function(DDM(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "    \n",
    "    detector_list.append('EDDM')\n",
    "    batches_detected.append(drift_detect_function(EDDM(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "    \n",
    "    detector_list.append('ADWIN')\n",
    "    batches_detected.append(drift_detect_function(ADWIN(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "    \n",
    "    detector_list.append('HDDM_A')\n",
    "    batches_detected.append(drift_detect_function(HDDM_A(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "    \n",
    "    detector_list.append('HDDM_W')\n",
    "    batches_detected.append(drift_detect_function(HDDM_W(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "\n",
    "batches_detected_clean = []\n",
    "for i in range(0, len(batches_detected)):\n",
    "    batches_detected_clean.append(list(dict.fromkeys(batches_detected[i])))\n",
    "\n",
    "classifier_list = list(itertools.chain.from_iterable(itertools.repeat(x, 5) for x in classifier_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021ce8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1df51464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_energy_eb_detectors = pd.DataFrame(list(zip(classifier_list, detector_list, batches_detected_clean)), columns =['Classifier', 'Detector', 'Batches_Detected'])\n",
    "# df_energy_eb_detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78101a12",
   "metadata": {},
   "source": [
    "# DDB Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6480c72",
   "metadata": {},
   "source": [
    "### Distribution of Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7edb220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.999)\n",
    "pca.fit(train_data)\n",
    "\n",
    "train_data_pca = pca.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ca6e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_train = sns.distplot(train_data).get_lines()[0].get_data()[1]\n",
    "plt.close()\n",
    "\n",
    "distribution_train_pca = sns.distplot(train_data_pca).get_lines()[0].get_data()[1]\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a365835",
   "metadata": {},
   "source": [
    "### Distribution Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa780f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# length_of_test should be around 15000 (best compromise between all testing sets)\n",
    "length_of_test = 15000\n",
    "distributions_bootstrapping = bootstrapping(train_data, bootstrapping_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08301abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distributions_bootstrapping_pca = bootstrapping(train_data, bootstrapping_samples=50, pca=pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "413f5f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:10<00:00,  8.55it/s]\n"
     ]
    }
   ],
   "source": [
    "distributions_test = []\n",
    "distributions_test_pca = []\n",
    "\n",
    "for i in tqdm(range(0, len(indexes_testing_batches))):\n",
    "    \n",
    "    index_current_testing_batch = indexes_testing_batches[i]\n",
    "    \n",
    "    testing_batch = test_data[(index_current_testing_batch[0]):(index_current_testing_batch[-1]+1)]\n",
    "\n",
    "    dist_test = sns.distplot(testing_batch).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    \n",
    "    dist_test_pca = sns.distplot(pca.transform(testing_batch)).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    \n",
    "    distributions_test.append(dist_test)\n",
    "    distributions_test_pca.append(dist_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309be88f",
   "metadata": {},
   "source": [
    "## EDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5a5ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject Null Hypothesis according to KS statistical test\n",
      "Reject Null Hypothesis according to KS statistical test\n"
     ]
    }
   ],
   "source": [
    "detected_drifts_ks = []\n",
    "detected_drifts_mw = []\n",
    "for i in range(0, len(distributions_test)):\n",
    "    if(ede_drift_detector(distribution_train, distributions_test[i], 'ks')==1):\n",
    "        detected_drifts_ks.append(i)\n",
    "    if(ede_drift_detector(distribution_train, distributions_test[i], 'mw')==1):\n",
    "        detected_drifts_mw.append(i)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "test = ['ks', 'mw']\n",
    "drifts = [detected_drifts_ks, detected_drifts_mw]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f50677e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ede_bootstrapping = pd.DataFrame({'detector' : 'ede',\n",
    "                                    'distance/test': test, \n",
    "                                    'Batches_Detected': drifts})\n",
    "# df_ede_bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff2995",
   "metadata": {},
   "source": [
    "## kdqTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee9e910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl_divergence : Drift Detected\n",
      "manhattan : Drift Detected\n",
      "chebyshev : Drift Detected\n",
      "cosine : Drift Detected\n",
      "squared_euclidean : Drift Detected\n",
      "bhattacharyya : Drift Detected\n"
     ]
    }
   ],
   "source": [
    "kl_drift = []\n",
    "mh_drift = []\n",
    "cbs_drift = []\n",
    "ksnk_drift = []\n",
    "csn_drift = []\n",
    "sqe_drift = []\n",
    "bct_drift = []\n",
    "\n",
    "for i in range(0, len(distributions_test)):\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'kl_divergence') == 1):\n",
    "        kl_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'manhattan') == 1):\n",
    "        mh_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'chebyshev') == 1):\n",
    "        cbs_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'kulsinski') == 1):\n",
    "        ksnk_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'cosine') == 1):\n",
    "        csn_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'squared_euclidean') == 1):\n",
    "        sqe_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'bhattacharyya') == 1):\n",
    "        bct_drift.append(i)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "distances = ['kl_div', 'manhattan', 'chebysev', 'kulsinski', 'cosine', 'sq_euclid', 'batthacrya']\n",
    "drifts = [kl_drift, mh_drift, cbs_drift, ksnk_drift, csn_drift, sqe_drift, bct_drift]\n",
    "df_kdqtrees_bootstrapping = pd.DataFrame({'detector' : 'kdqTrees',\n",
    "                                        'distance/test': distances, \n",
    "                                        'Batches_Detected': drifts\n",
    "                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4b4e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kdqtrees_bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3141b18",
   "metadata": {},
   "source": [
    "## PCA-kdq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fa89079",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_drift = []\n",
    "mh_drift = []\n",
    "cbs_drift = []\n",
    "ksnk_drift = []\n",
    "csn_drift = []\n",
    "sqe_drift = []\n",
    "bct_drift = []\n",
    "\n",
    "for i in range(0, len(distributions_test_pca)):\n",
    "\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'kl_divergence') == 1):\n",
    "        kl_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'manhattan') == 1):\n",
    "        mh_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'chebyshev') == 1):\n",
    "        cbs_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'kulsinski') == 1):\n",
    "        ksnk_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'cosine') == 1):\n",
    "        csn_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'squared_euclidean') == 1):\n",
    "        sqe_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'bhattacharyya') == 1):\n",
    "        bct_drift.append(i)\n",
    "    clear_output(wait=False)\n",
    "\n",
    "distances = ['kl_div', 'manhattan', 'chebysev', 'kulsinski', 'cosine', 'sq_euclid', 'batthacrya']\n",
    "drifts = [kl_drift, mh_drift, cbs_drift, ksnk_drift, csn_drift, sqe_drift, bct_drift]\n",
    "df_pca_bootstrapping = pd.DataFrame({'detector' : 'pca',\n",
    "                                     'distance/test': distances, \n",
    "                                     'Batches_Detected': drifts\n",
    "                                })\n",
    "\n",
    "merged_results = pd.concat([df_ede_bootstrapping, df_kdqtrees_bootstrapping, df_pca_bootstrapping])\n",
    "merged_results = merged_results.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0785ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pca_bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52702326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy_ddb_detectors = pd.concat([df_ede_bootstrapping, df_kdqtrees_bootstrapping, df_pca_bootstrapping])\n",
    "#df_energy_ddb_detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671642f5",
   "metadata": {},
   "source": [
    "# Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6deb5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_batches_with_drift = 84 # there are 84 batches with drift because 3 feature start changing their behaviour after the 2nd of May 1997\n",
    "drift_start = 2 # drift starts at batch 2, which is the week including the 2nd of May 1997 (30.04.1997-06.05.1997) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78a7b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_erb = []\n",
    "fpr_erb = []\n",
    "\n",
    "latency_ddb = []\n",
    "fpr_ddb = []\n",
    "\n",
    "for i in range(0, len(list(df_energy_eb_detectors.Batches_Detected))):\n",
    "    latency_erb.append(compute_metric_latency(list(df_energy_eb_detectors.Batches_Detected)[i], no_batches_with_drift, drift_start))\n",
    "    fpr_erb.append(compute_metric_false_positive(list(df_energy_eb_detectors.Batches_Detected)[i], drift_start))\n",
    "\n",
    "for i in range(0, len(list(df_energy_ddb_detectors.Batches_Detected))):\n",
    "    latency_ddb.append(compute_metric_latency(list(df_energy_ddb_detectors.Batches_Detected)[i], no_batches_with_drift, drift_start))\n",
    "    fpr_ddb.append(compute_metric_false_positive(list(df_energy_ddb_detectors.Batches_Detected)[i], drift_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f22bf79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Detector</th>\n",
       "      <th>Batches_Detected</th>\n",
       "      <th>latency</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[2, 4, 7, 9, 10, 11, 12, 15, 18, 20, 21, 22, 2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[2, 3, 4, 8, 9, 11, 12, 14, 18, 21, 22, 23, 36...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[2, 5, 7, 8, 9, 10, 12, 15, 16, 17, 18, 20, 22...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[2, 3, 4, 6, 8, 9, 14, 18, 19, 23, 25, 34, 48,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 18, 20, 21...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[2, 3, 4, 8, 9, 11, 12, 14, 18, 20, 21, 22, 23...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[0, 1, 2, 7, 8, 9, 10, 12, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[2, 3, 4, 6, 8, 9, 11, 14, 15, 19, 21, 22, 23,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[0, 1, 2, 5, 6, 7, 9, 10, 12, 15, 16, 17, 19, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[2, 3, 8, 9, 14, 16, 17, 18, 21, 22, 23, 24, 2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier Detector                                   Batches_Detected  \\\n",
       "0      NaiveBayes      DDM  [2, 4, 7, 9, 10, 11, 12, 15, 18, 20, 21, 22, 2...   \n",
       "1      NaiveBayes     EDDM  [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "2      NaiveBayes    ADWIN  [2, 3, 4, 8, 9, 11, 12, 14, 18, 21, 22, 23, 36...   \n",
       "3      NaiveBayes   HDDM_A  [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 1...   \n",
       "4      NaiveBayes   HDDM_W  [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 1...   \n",
       "5   HoeffdingTree      DDM  [2, 5, 7, 8, 9, 10, 12, 15, 16, 17, 18, 20, 22...   \n",
       "6   HoeffdingTree     EDDM  [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "7   HoeffdingTree    ADWIN  [2, 3, 4, 6, 8, 9, 14, 18, 19, 23, 25, 34, 48,...   \n",
       "8   HoeffdingTree   HDDM_A  [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15...   \n",
       "9   HoeffdingTree   HDDM_W  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15,...   \n",
       "10       Adaboost      DDM  [2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 18, 20, 21...   \n",
       "11       Adaboost     EDDM  [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 1...   \n",
       "12       Adaboost    ADWIN  [2, 3, 4, 8, 9, 11, 12, 14, 18, 20, 21, 22, 23...   \n",
       "13       Adaboost   HDDM_A  [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, ...   \n",
       "14       Adaboost   HDDM_W  [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, ...   \n",
       "15        XGBoost      DDM  [0, 1, 2, 7, 8, 9, 10, 12, 15, 16, 17, 18, 19,...   \n",
       "16        XGBoost     EDDM  [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "17        XGBoost    ADWIN  [2, 3, 4, 6, 8, 9, 11, 14, 15, 19, 21, 22, 23,...   \n",
       "18        XGBoost   HDDM_A  [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 1...   \n",
       "19        XGBoost   HDDM_W  [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, ...   \n",
       "20       LightGBM      DDM  [0, 1, 2, 5, 6, 7, 9, 10, 12, 15, 16, 17, 19, ...   \n",
       "21       LightGBM     EDDM  [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15...   \n",
       "22       LightGBM    ADWIN  [2, 3, 8, 9, 14, 16, 17, 18, 21, 22, 23, 24, 2...   \n",
       "23       LightGBM   HDDM_A  [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, ...   \n",
       "24       LightGBM   HDDM_W  [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, ...   \n",
       "\n",
       "    latency  fpr  \n",
       "0       0.0  0.0  \n",
       "1       0.0  1.0  \n",
       "2       0.0  0.0  \n",
       "3       0.0  1.0  \n",
       "4       0.0  1.0  \n",
       "5       0.0  0.0  \n",
       "6       0.0  1.0  \n",
       "7       0.0  0.0  \n",
       "8       0.0  1.0  \n",
       "9       0.0  1.0  \n",
       "10      0.0  0.0  \n",
       "11      0.0  1.0  \n",
       "12      0.0  0.0  \n",
       "13      0.0  1.0  \n",
       "14      0.0  1.0  \n",
       "15      0.0  1.0  \n",
       "16      0.0  1.0  \n",
       "17      0.0  0.0  \n",
       "18      0.0  1.0  \n",
       "19      0.0  1.0  \n",
       "20      0.0  1.0  \n",
       "21      0.0  1.0  \n",
       "22      0.0  0.0  \n",
       "23      0.0  1.0  \n",
       "24      0.0  1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energy_eb_detectors['latency'] = latency_erb\n",
    "df_energy_eb_detectors['fpr'] = fpr_erb\n",
    "df_energy_eb_detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "025c8571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>distance/test</th>\n",
       "      <th>Batches_Detected</th>\n",
       "      <th>latency</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ede</td>\n",
       "      <td>ks</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ede</td>\n",
       "      <td>mw</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>kl_div</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>chebysev</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>kulsinski</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>sq_euclid</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>batthacrya</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca</td>\n",
       "      <td>kl_div</td>\n",
       "      <td>[0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pca</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pca</td>\n",
       "      <td>chebysev</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pca</td>\n",
       "      <td>kulsinski</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pca</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pca</td>\n",
       "      <td>sq_euclid</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pca</td>\n",
       "      <td>batthacrya</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   detector distance/test                                   Batches_Detected  \\\n",
       "0       ede            ks  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1       ede            mw  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "0  kdqTrees        kl_div  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  kdqTrees     manhattan  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  kdqTrees      chebysev  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  kdqTrees     kulsinski                                                 []   \n",
       "4  kdqTrees        cosine  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "5  kdqTrees     sq_euclid  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "6  kdqTrees    batthacrya  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "0       pca        kl_div  [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "1       pca     manhattan  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2       pca      chebysev  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3       pca     kulsinski  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 1...   \n",
       "4       pca        cosine  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "5       pca     sq_euclid  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "6       pca    batthacrya  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "            latency               fpr  \n",
       "0               0.0               1.0  \n",
       "1               0.0               1.0  \n",
       "0               0.0               1.0  \n",
       "1               0.0               1.0  \n",
       "2               0.0               1.0  \n",
       "3  nothing_detected  nothing_detected  \n",
       "4               0.0               1.0  \n",
       "5               0.0               1.0  \n",
       "6               0.0               1.0  \n",
       "0               0.0               1.0  \n",
       "1               0.0               1.0  \n",
       "2               0.0               1.0  \n",
       "3               0.0                 0  \n",
       "4               0.0               1.0  \n",
       "5               0.0               1.0  \n",
       "6               0.0               1.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energy_ddb_detectors['latency'] = latency_ddb\n",
    "df_energy_ddb_detectors['fpr'] = fpr_ddb\n",
    "df_energy_ddb_detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160905b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8356f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa9d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
