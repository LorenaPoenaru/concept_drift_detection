{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174d5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from skmultiflow.drift_detection import DDM\n",
    "from skmultiflow.drift_detection import EDDM\n",
    "from skmultiflow.drift_detection import ADWIN\n",
    "from skmultiflow.drift_detection import HDDM_A\n",
    "from skmultiflow.drift_detection import HDDM_W\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from math import log2\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from scipy.spatial.distance import chebyshev\n",
    "from scipy.spatial.distance import kulsinski\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import sqeuclidean\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7daf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    return sum(p[0][i] * log2(p[0][i]/q[0][i]) for i in range(len(p[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ca4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bhattacharyya(p, q):\n",
    "    return -np.log(sum(np.square(p[0][i]*1.0*q[0][i]) for i in range(len(p[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e2c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(X_train, bootstrapping_samples, pca=None):\n",
    "    # Extract distributions of 50 random training subsets\n",
    "    distributions_bootstrapping = []\n",
    "    for i in range(0, bootstrapping_samples):\n",
    "        # generate random number between 0 and length_of_train-length_of_test in order to have a sample of size length_of_test\n",
    "        rand = random.randint(0,len(X_train)-length_of_test)\n",
    "        # extract the distribution from the training samples random number:random number + length_of_test by means of histogram\n",
    "        if pca is not None:\n",
    "            bootstrapping_input = pca.transform(X_train[rand:rand+length_of_test])\n",
    "        else:\n",
    "            bootstrapping_input = X_train[rand:rand+length_of_test]\n",
    "        dist = sns.distplot(bootstrapping_input).get_lines()[0].get_data()[1]\n",
    "        # store distribution\n",
    "        distributions_bootstrapping.append(dist)\n",
    "        plt.close()\n",
    "    return distributions_bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e977a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdqtrees_bootstrapping(distrib_X_train, distrib_X_test, distributions_bootstrapping, distance):\n",
    "    \n",
    "    # option to choose the similarity distance\n",
    "    \n",
    "    if(distance == 'kl_divergence'):\n",
    "        similarity_metric = kl_divergence\n",
    "    elif(distance == 'manhattan'):\n",
    "        similarity_metric = manhattan_distances\n",
    "    elif(distance == 'chebyshev'):\n",
    "        similarity_metric = chebyshev\n",
    "    elif(distance == 'kulsinski'):\n",
    "        similarity_metric = kulsinski\n",
    "    elif(distance == 'cosine'):\n",
    "        similarity_metric = cosine\n",
    "    elif(distance == 'squared_euclidean'):\n",
    "        similarity_metric = sqeuclidean\n",
    "    elif(distance == 'bhattacharyya'):\n",
    "        similarity_metric = bhattacharyya\n",
    "    \n",
    "    # Bootstrapping technique to define critical region\n",
    "    \n",
    "    dist_bootstrapping = []\n",
    "    \n",
    "    # Calculate similarity distance between training set and each of the 50 training subsets\n",
    "    for i in range(0, len(distributions_bootstrapping)):\n",
    "        dist_bootstrapping.append(similarity_metric([distrib_X_train], [distributions_bootstrapping[i]]))\n",
    "    \n",
    "    \n",
    "    # Define Critical Region\n",
    "    critical_region = np.max(dist_bootstrapping)\n",
    "    \n",
    "    # Detect Drifts between train and test\n",
    "    \n",
    "    drift_batch = None\n",
    "    \n",
    "    # Calculate distance between train and test distributions\n",
    "    \n",
    "    similarity_metric_train_test = similarity_metric([distrib_X_train], [distrib_X_test])\n",
    "    \n",
    "    if(similarity_metric_train_test>critical_region):\n",
    "        print(distance + \" : Drift Detected\" )\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1c1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_false_positive(array_batches, drift_start):\n",
    "        \n",
    "    if(len(array_batches)>0): \n",
    "        \n",
    "        if(len([x for x in array_batches if x<drift_start])>0):\n",
    "            return(len([x for x in array_batches if x<drift_start])/drift_start)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    else:\n",
    "        return 'nothing_detected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009b4031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ede_drift_detector(distrib_X_train, distrib_X_test, statistical_test):\n",
    "\n",
    "    if(statistical_test == 'ks'):\n",
    "        stat_test = stats.kstest\n",
    "    elif(statistical_test == 'mw'):\n",
    "        stat_test = stats.mannwhitneyu\n",
    "    \n",
    "    v, p = stat_test(distrib_X_train, distrib_X_test)\n",
    "        \n",
    "    \n",
    "    if(p<=0.05):\n",
    "        print(\"Reject Null Hypothesis according to KS statistical test\")\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37fb2c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_latency(array_batches, no_batches_with_drift, drift_start):\n",
    "    \n",
    "    if(len(array_batches)>0):  \n",
    "        #print(np.array(array_pr)>=drift_type_start)\n",
    "        #print(np.argwhere(np.array(array_pr)>=drift_type_start).size==0)\n",
    "        \n",
    "        if(np.argwhere(np.array(array_batches)>=drift_start).size==0):\n",
    "            latency_score = 'nothing_detected' \n",
    "        else:\n",
    "            batch_drift_detected = array_batches[np.argwhere(np.array(array_batches)>=drift_start)[0][0]]\n",
    "            latency_score = (batch_drift_detected - drift_start)/no_batches_with_drift\n",
    "        return latency_score\n",
    "    else:\n",
    "        return 'nothing_detected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a42955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_detect_function(drift_detector, y_true, y_pred, no_batches):\n",
    "    batches_with_drift = []\n",
    "    for i in range(0, no_batches):\n",
    "        label_difference = abs(y_true[i] - y_pred[i])\n",
    "        #print(label_difference)\n",
    "        \n",
    "        for j in range(0, len(label_difference)):\n",
    "            drift_detector.add_element(list(label_difference)[j])\n",
    "\n",
    "            if(drift_detector.detected_change()):\n",
    "                batches_with_drift.append(i)\n",
    "    return batches_with_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1a8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADWIN has: 1 for correct prediction and 0 for incorrect prediction\n",
    "def drift_detect_function_ADWIN(drift_detector, y_true, y_pred, no_batches):\n",
    "    \n",
    "    batches_with_drift = []\n",
    "    for i in range(0, no_batches):\n",
    "        label_difference = abs(y_true[i] - y_pred[i])\n",
    "        label_difference_final = 1 - label_difference\n",
    "    \n",
    "        for j in range(0, len(label_difference_final)):\n",
    "            drift_detector.add_element(list(label_difference_final)[j])\n",
    "            if(drift_detector.detected_change()):\n",
    "                batches_with_drift.append(i)\n",
    "    return batches_with_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c29040",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6411ed0",
   "metadata": {},
   "source": [
    "# Airlines Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35857dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_airlines = arff.loadarff('../airlines.arff')\n",
    "df_airlines = pd.DataFrame(data_airlines[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b680ef",
   "metadata": {},
   "source": [
    "### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ade5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df_airlines['Delay'] = labelencoder.fit_transform(df_airlines['Delay'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd88b93",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e95660",
   "metadata": {},
   "source": [
    "### Feature Cardinality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f26462ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_airlines.Airline.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52fdaf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_airlines.AirportFrom.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269ef32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_airlines.AirportTo.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2fb3b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_airlines[(df_airlines.Flight == 269.0) & (df_airlines.Airline == list(df_airlines.Airline)[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c46b9",
   "metadata": {},
   "source": [
    "Issue: Airport From and Airport To have 293 different values each, which makes them high cardinal features. This results in adding almost 600 new features through One Hot Encoding, which could make the model suffer from the curse of dimensionality. \n",
    "\n",
    "Solution: we can remove AirportTo and AirportFrom, since the flight number + airline is the same for each source and destination. However, the flight number can be the same for multiple airlines, so Airline should not be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7bd32",
   "metadata": {},
   "source": [
    "### Remove high cardinality features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14b4ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airlines = df_airlines.drop(['AirportFrom', 'AirportTo'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a8947",
   "metadata": {},
   "source": [
    "### One Hot Encoding on Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a66c56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_data = pd.get_dummies(df_airlines, columns = ['Airline'])\n",
    "df = one_hot_encoded_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7396c66",
   "metadata": {},
   "source": [
    "### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbffe9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f5b751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(df.drop(['DayOfWeek', 'Delay'], axis = 1))\n",
    "df_scale = scaler.transform(df.drop(['DayOfWeek', 'Delay'], axis = 1))\n",
    "df_features_train_test = pd.DataFrame(df_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dad10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_train_test = df['Delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b5c42",
   "metadata": {},
   "source": [
    "## Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ab9c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numbers here correspond to the exact moment when the second week starts and \n",
    "# the exact moment for each day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65ee951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# including Day 1 & 2 of the second week (Monday and Tuesday) into the training set\n",
    "df_train_1 = df_features_train_test[85190:120388] \n",
    "df_labels_train_1 = df_labels_train_test[85190:120388]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c5909f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data corresponding to Wednesday\n",
    "df_test_wed = df_features_train_test[120388:137920]\n",
    "df_labels_test_wed = df_labels_train_test[120388:137920]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3b2ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data corresponding to Thursday\n",
    "df_test_thu = df_features_train_test[137920:155976]\n",
    "df_labels_test_thu = df_labels_train_test[137920:155976]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1564847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data corresponding to Friday\n",
    "df_test_fri = df_features_train_test[155976:174115]\n",
    "df_labels_test_fri = df_labels_train_test[155976:174115]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed022832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data corresponding to Saturday\n",
    "df_test_sat = df_features_train_test[174115:188415]\n",
    "df_labels_test_sat = df_labels_train_test[174115:188415]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfdcab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data corresponding to Sunday\n",
    "df_test_sun = df_features_train_test[188415:205551]\n",
    "df_labels_test_sun = df_labels_train_test[188415:205551]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e28a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_total = [df_test_wed, df_test_thu, df_test_fri, df_test_sat, df_test_sun]\n",
    "df_test_labels_total = [df_labels_test_wed, df_labels_test_thu, df_labels_test_fri, df_labels_test_sat, df_labels_test_sun]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2a1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c805131e",
   "metadata": {},
   "source": [
    "# EB Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe490e8a",
   "metadata": {},
   "source": [
    "### Train Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55bc2a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:05:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "naive_bayes = gnb.fit(df_train_1, df_labels_train_1)\n",
    "\n",
    "ht = HoeffdingTreeClassifier()\n",
    "hoeffding_tree = ht.fit(np.array(df_train_1), np.array(df_labels_train_1))\n",
    "\n",
    "adb = AdaBoostClassifier(n_estimators= 100, random_state=0)\n",
    "adaboost = adb.fit(df_train_1, df_labels_train_1)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgboost = xgb.fit(df_train_1, df_labels_train_1)\n",
    "\n",
    "lgb = LGBMClassifier()\n",
    "lightgbm = lgb.fit(df_train_1, df_labels_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab6535",
   "metadata": {},
   "source": [
    "### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "753f12b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_naivebayes = []\n",
    "y_pred_hoftree = []\n",
    "y_pred_adaboost = []\n",
    "y_pred_xgboost = []\n",
    "y_pred_lightgbm = []\n",
    "\n",
    "for i in tqdm(range(0, len(df_test_total))):\n",
    "    # naive bayes\n",
    "    y_pred_nb = naive_bayes.predict(df_test_total[i])\n",
    "    y_pred_naivebayes.append(y_pred_nb)\n",
    "\n",
    "    # hoeffding tree\n",
    "    y_pred_ht = hoeffding_tree.predict(np.array(df_test_total[i]))\n",
    "    y_pred_hoftree.append(y_pred_ht)\n",
    "    # adaboost\n",
    "    y_pred_adb = adaboost.predict(df_test_total[i])\n",
    "    y_pred_adaboost.append(y_pred_adb)\n",
    "    # xgboost\n",
    "    y_pred_xgb = xgboost.predict(df_test_total[i])\n",
    "    y_pred_xgboost.append(y_pred_xgb)\n",
    "    # lightgbm\n",
    "    y_pred_lgbm = lightgbm.predict(df_test_total[i])\n",
    "    y_pred_lightgbm.append(y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "026812c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dict = {'NaiveBayes': y_pred_naivebayes, \n",
    "                   'HoeffdingTree' : y_pred_hoftree, \n",
    "                   'Adaboost' : y_pred_adaboost,\n",
    "                   'XGBoost' : y_pred_xgboost,\n",
    "                   'LightGBM' : y_pred_lightgbm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c5b2d",
   "metadata": {},
   "source": [
    "### Detect Drifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3534d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_batches = len(df_test_labels_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b660f597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier_list = []\n",
    "detector_list = []\n",
    "batches_detected = []\n",
    "\n",
    "for i in range(0, len(list(y_pred_dict.keys()))):\n",
    "    classifier_list.append(list(y_pred_dict.keys())[i])\n",
    "    \n",
    "    detector_list.append('DDM')\n",
    "    batches_detected.append(drift_detect_function(DDM(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "    \n",
    "    detector_list.append('EDDM')\n",
    "    batches_detected.append(drift_detect_function(EDDM(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "    \n",
    "    detector_list.append('ADWIN')\n",
    "    batches_detected.append(drift_detect_function(ADWIN(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "    \n",
    "    detector_list.append('HDDM_A')\n",
    "    batches_detected.append(drift_detect_function(HDDM_A(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "    \n",
    "    detector_list.append('HDDM_W')\n",
    "    batches_detected.append(drift_detect_function(HDDM_W(), df_test_labels_total, list(y_pred_dict.values())[i], no_batches))\n",
    "\n",
    "batches_detected_clean = []\n",
    "for i in range(0, len(batches_detected)):\n",
    "    batches_detected_clean.append(list(dict.fromkeys(batches_detected[i])))\n",
    "\n",
    "classifier_list = list(itertools.chain.from_iterable(itertools.repeat(x, 5) for x in classifier_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222825a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41d9264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airlines_eb_detectors = pd.DataFrame(list(zip(classifier_list, detector_list, batches_detected_clean)), columns =['Classifier', 'Detector', 'Batches_Detected'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b24574",
   "metadata": {},
   "source": [
    "# DDB Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d9dbc",
   "metadata": {},
   "source": [
    "Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "048d2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8b118",
   "metadata": {},
   "source": [
    "### Distribution of Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9dfd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.999)\n",
    "pca.fit(df_train_1)\n",
    "\n",
    "df_train_1_pca = pca.transform(df_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d47820e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_train = sns.distplot(df_train_1).get_lines()[0].get_data()[1]\n",
    "plt.close()\n",
    "\n",
    "distribution_train_pca = sns.distplot(df_train_1_pca).get_lines()[0].get_data()[1]\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73ba7f",
   "metadata": {},
   "source": [
    "### Distribution Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb5e0e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# length_of_test should be around 15000 (best compromise between all testing sets)\n",
    "length_of_test = 15000\n",
    "distributions_bootstrapping = bootstrapping(df_train_1, bootstrapping_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc6355e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distributions_bootstrapping_pca = bootstrapping(df_train_1, bootstrapping_samples=50, pca=pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d31dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d89c1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distributions_test = []\n",
    "distributions_test_pca = []\n",
    "\n",
    "for i in range(0, len(df_test_total)):\n",
    "    dist_test = sns.distplot(df_test_total[i]).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    \n",
    "    dist_test_pca = sns.distplot(pca.transform(df_test_total[i])).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    \n",
    "    distributions_test.append(dist_test)\n",
    "    distributions_test_pca.append(dist_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014ba5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "027453e8",
   "metadata": {},
   "source": [
    "## EDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f222678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_drifts_ks = []\n",
    "detected_drifts_mw = []\n",
    "for i in range(0, len(distributions_test)):\n",
    "    if(ede_drift_detector(distribution_train, distributions_test[i], 'ks')==1):\n",
    "        detected_drifts_ks.append(i)\n",
    "    if(ede_drift_detector(distribution_train, distributions_test[i], 'mw')==1):\n",
    "        detected_drifts_mw.append(i)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "test = ['ks', 'mw']\n",
    "drifts = [detected_drifts_ks, detected_drifts_mw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4b32da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ede_bootstrapping = pd.DataFrame({'detector' : 'ede',\n",
    "                                    'distance/test': test, \n",
    "                                    'Batches_Detected': drifts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e739f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ede_bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad208174",
   "metadata": {},
   "source": [
    "## kdqTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a235e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_drift = []\n",
    "mh_drift = []\n",
    "cbs_drift = []\n",
    "ksnk_drift = []\n",
    "csn_drift = []\n",
    "sqe_drift = []\n",
    "bct_drift = []\n",
    "\n",
    "for i in range(0, len(distributions_test)):\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'kl_divergence') == 1):\n",
    "        kl_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'manhattan') == 1):\n",
    "        mh_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'chebyshev') == 1):\n",
    "        cbs_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'kulsinski') == 1):\n",
    "        ksnk_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'cosine') == 1):\n",
    "        csn_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'squared_euclidean') == 1):\n",
    "        sqe_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train, distributions_test[i], distributions_bootstrapping, 'bhattacharyya') == 1):\n",
    "        bct_drift.append(i)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "distances = ['kl_div', 'manhattan', 'chebysev', 'kulsinski', 'cosine', 'sq_euclid', 'batthacrya']\n",
    "drifts = [kl_drift, mh_drift, cbs_drift, ksnk_drift, csn_drift, sqe_drift, bct_drift]\n",
    "df_kdqtrees_bootstrapping = pd.DataFrame({'detector' : 'kdqTrees',\n",
    "                                        'distance/test': distances, \n",
    "                                        'Batches_Detected': drifts\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d1f6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kdqtrees_bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687acd47",
   "metadata": {},
   "source": [
    "## PCA-kdq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9c730a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_drift = []\n",
    "mh_drift = []\n",
    "cbs_drift = []\n",
    "ksnk_drift = []\n",
    "csn_drift = []\n",
    "sqe_drift = []\n",
    "bct_drift = []\n",
    "\n",
    "for i in range(0, len(distributions_test_pca)):\n",
    "\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'kl_divergence') == 1):\n",
    "        kl_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'manhattan') == 1):\n",
    "        mh_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'chebyshev') == 1):\n",
    "        cbs_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'kulsinski') == 1):\n",
    "        ksnk_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'cosine') == 1):\n",
    "        csn_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'squared_euclidean') == 1):\n",
    "        sqe_drift.append(i)\n",
    "    if(kdqtrees_bootstrapping(distribution_train_pca, distributions_test_pca[i], distributions_bootstrapping_pca, 'bhattacharyya') == 1):\n",
    "        bct_drift.append(i)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "distances = ['kl_div', 'manhattan', 'chebysev', 'kulsinski', 'cosine', 'sq_euclid', 'batthacrya']\n",
    "drifts = [kl_drift, mh_drift, cbs_drift, ksnk_drift, csn_drift, sqe_drift, bct_drift]\n",
    "df_pca_bootstrapping = pd.DataFrame({'detector' : 'pca',\n",
    "                                     'distance/test': distances, \n",
    "                                     'Batches_Detected': drifts\n",
    "                                })\n",
    "\n",
    "merged_results = pd.concat([df_ede_bootstrapping, df_kdqtrees_bootstrapping, df_pca_bootstrapping])\n",
    "merged_results = merged_results.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b35981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airlines_ddb_detectors = pd.concat([df_ede_bootstrapping, df_kdqtrees_bootstrapping, df_pca_bootstrapping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54aeae",
   "metadata": {},
   "source": [
    "# Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaa0cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_batches_with_drift = 3 # there are 3 testing batches with drift corresponding to Friday, Saturday and Sunday\n",
    "drift_start = 2 # drift starts at batch 2, corresponding to Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "530e01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_erb = []\n",
    "fpr_erb = []\n",
    "\n",
    "latency_ddb = []\n",
    "fpr_ddb = []\n",
    "\n",
    "for i in range(0, len(list(df_airlines_eb_detectors.Batches_Detected))):\n",
    "    latency_erb.append(compute_metric_latency(list(df_airlines_eb_detectors.Batches_Detected)[i], no_batches_with_drift, drift_start))\n",
    "    fpr_erb.append(compute_metric_false_positive(list(df_airlines_eb_detectors.Batches_Detected)[i], drift_start))\n",
    "\n",
    "for i in range(0, len(list(df_airlines_ddb_detectors.Batches_Detected))):\n",
    "    latency_ddb.append(compute_metric_latency(list(df_airlines_ddb_detectors.Batches_Detected)[i], no_batches_with_drift, drift_start))\n",
    "    fpr_ddb.append(compute_metric_false_positive(list(df_airlines_ddb_detectors.Batches_Detected)[i], drift_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9467c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Detector</th>\n",
       "      <th>Batches_Detected</th>\n",
       "      <th>latency</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[0, 4]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[0]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HoeffdingTree</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 2, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 4]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>DDM</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>EDDM</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>ADWIN</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HDDM_A</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HDDM_W</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier Detector Batches_Detected           latency  fpr\n",
       "0      NaiveBayes      DDM           [0, 4]          0.666667  0.5\n",
       "1      NaiveBayes     EDDM              [0]  nothing_detected  0.5\n",
       "2      NaiveBayes    ADWIN  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "3      NaiveBayes   HDDM_A  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "4      NaiveBayes   HDDM_W  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "5   HoeffdingTree      DDM              [0]  nothing_detected  0.5\n",
       "6   HoeffdingTree     EDDM  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "7   HoeffdingTree    ADWIN  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "8   HoeffdingTree   HDDM_A  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "9   HoeffdingTree   HDDM_W  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "10       Adaboost      DDM  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "11       Adaboost     EDDM     [0, 1, 2, 4]               0.0  1.0\n",
       "12       Adaboost    ADWIN  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "13       Adaboost   HDDM_A  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "14       Adaboost   HDDM_W  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "15        XGBoost      DDM        [0, 1, 2]               0.0  1.0\n",
       "16        XGBoost     EDDM        [0, 1, 4]          0.666667  1.0\n",
       "17        XGBoost    ADWIN  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "18        XGBoost   HDDM_A  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "19        XGBoost   HDDM_W  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "20       LightGBM      DDM        [0, 1, 2]               0.0  1.0\n",
       "21       LightGBM     EDDM  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "22       LightGBM    ADWIN  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "23       LightGBM   HDDM_A  [0, 1, 2, 3, 4]               0.0  1.0\n",
       "24       LightGBM   HDDM_W  [0, 1, 2, 3, 4]               0.0  1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airlines_eb_detectors['latency'] = latency_erb\n",
    "df_airlines_eb_detectors['fpr'] = fpr_erb\n",
    "df_airlines_eb_detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0b2a4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>distance/test</th>\n",
       "      <th>Batches_Detected</th>\n",
       "      <th>latency</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ede</td>\n",
       "      <td>ks</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ede</td>\n",
       "      <td>mw</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>kl_div</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>chebysev</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>kulsinski</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>sq_euclid</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kdqTrees</td>\n",
       "      <td>batthacrya</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pca</td>\n",
       "      <td>kl_div</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pca</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pca</td>\n",
       "      <td>chebysev</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pca</td>\n",
       "      <td>kulsinski</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pca</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pca</td>\n",
       "      <td>sq_euclid</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pca</td>\n",
       "      <td>batthacrya</td>\n",
       "      <td>[]</td>\n",
       "      <td>nothing_detected</td>\n",
       "      <td>nothing_detected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   detector distance/test Batches_Detected           latency               fpr\n",
       "0       ede            ks               []  nothing_detected  nothing_detected\n",
       "1       ede            mw               []  nothing_detected  nothing_detected\n",
       "0  kdqTrees        kl_div               []  nothing_detected  nothing_detected\n",
       "1  kdqTrees     manhattan               []  nothing_detected  nothing_detected\n",
       "2  kdqTrees      chebysev               []  nothing_detected  nothing_detected\n",
       "3  kdqTrees     kulsinski               []  nothing_detected  nothing_detected\n",
       "4  kdqTrees        cosine               []  nothing_detected  nothing_detected\n",
       "5  kdqTrees     sq_euclid               []  nothing_detected  nothing_detected\n",
       "6  kdqTrees    batthacrya               []  nothing_detected  nothing_detected\n",
       "0       pca        kl_div               []  nothing_detected  nothing_detected\n",
       "1       pca     manhattan               []  nothing_detected  nothing_detected\n",
       "2       pca      chebysev               []  nothing_detected  nothing_detected\n",
       "3       pca     kulsinski               []  nothing_detected  nothing_detected\n",
       "4       pca        cosine               []  nothing_detected  nothing_detected\n",
       "5       pca     sq_euclid               []  nothing_detected  nothing_detected\n",
       "6       pca    batthacrya               []  nothing_detected  nothing_detected"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airlines_ddb_detectors['latency'] = latency_ddb\n",
    "df_airlines_ddb_detectors['fpr'] = fpr_ddb\n",
    "df_airlines_ddb_detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813b96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8caf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
